{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075240e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189e202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07685532",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"v2_data/training_data_2025-08-17.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f06681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "training_data = pd.read_csv(training_path)\n",
    "training_data = training_data.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70a8c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_issues(df):\n",
    "    \"\"\"Check for common missing/null/error values in the DataFrame and print summary. Also print rows with errors.\"\"\"\n",
    "    import numpy as np\n",
    "    print(\"--- Data Issues Summary ---\")\n",
    "    # Check for NaN values\n",
    "    nan_counts = df.isna().sum()\n",
    "    if nan_counts.any():\n",
    "        print(\"NaN values found:\")\n",
    "        print(nan_counts[nan_counts > 0])\n",
    "    else:\n",
    "        print(\"No NaN values found.\")\n",
    "\n",
    "    # Check for infinite values\n",
    "    inf_counts = np.isinf(df.select_dtypes(include=[float, int])).sum()\n",
    "    if inf_counts.any():\n",
    "        print(\"Infinite values found:\")\n",
    "        print(inf_counts[inf_counts > 0])\n",
    "    else:\n",
    "        print(\"No infinite values found.\")\n",
    "\n",
    "    # Check for string 'inf', '-inf', 'nan', 'None', or empty string\n",
    "    error_strings = ['inf', '-inf', 'nan', 'None', '']\n",
    "    error_rows = set()\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        for err in error_strings:\n",
    "            mask = (df[col] == err)\n",
    "            count = mask.sum()\n",
    "            if count > 0:\n",
    "                print(f\"Column '{col}' has {count} occurrences of '{err}'\")\n",
    "                error_rows.update(df[mask].index.tolist())\n",
    "\n",
    "    # Collect all error rows (NaN, inf, error strings)\n",
    "    nan_rows = set(df[df.isna().any(axis=1)].index.tolist())\n",
    "    inf_rows = set(df[np.isinf(df.select_dtypes(include=[float, int])).any(axis=1)].index.tolist())\n",
    "    all_error_rows = nan_rows.union(inf_rows).union(error_rows)\n",
    "\n",
    "    print(\"--- End of Data Issues Summary ---\")\n",
    "    if all_error_rows:\n",
    "        print(f\"\\nDetailed view of rows with data errors ({len(all_error_rows)} rows) saved to .csv:\")\n",
    "        df.loc[sorted(all_error_rows)].to_csv(\"data_errors.csv\", index=False)\n",
    "    else:\n",
    "        print(\"No rows with data errors found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f85c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Issues Summary ---\n",
      "NaN values found:\n",
      "ph_kd_ratio_std_Team0    3\n",
      "dtype: int64\n",
      "Infinite values found:\n",
      "ph_kd_ratio_max_Team0     3\n",
      "ph_kd_ratio_mean_Team0    3\n",
      "dtype: int64\n",
      "--- End of Data Issues Summary ---\n",
      "\n",
      "Detailed view of rows with data errors (3 rows) saved to .csv:\n"
     ]
    }
   ],
   "source": [
    "check_data_issues(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for v1\n",
    "training_data['ph_kd_ratio_max_Team0'] = training_data['ph_kd_ratio_max_Team0'].replace('inf', 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9334c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'quick_Test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtraining_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquick_Test.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'quick_Test.csv'"
     ]
    }
   ],
   "source": [
    "training_data.to_csv(\"quick_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite values:\n",
      " Series([], dtype: int64)\n",
      "Unnamed: 0                          int64\n",
      "match_id                            int64\n",
      "p_total_time_played_min_Team0       int64\n",
      "p_total_time_played_min_Team1       int64\n",
      "p_total_time_played_max_Team0       int64\n",
      "                                   ...   \n",
      "ph_win_rate_ratio_median_Team0    float64\n",
      "ph_win_rate_ratio_median_Team1    float64\n",
      "ph_win_rate_ratio_q75_Team0       float64\n",
      "ph_win_rate_ratio_q75_Team1       float64\n",
      "team_0_win                         object\n",
      "Length: 133, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# This was resolved earlier in the pipeline for future datasets\n",
    "# # Check for infinite values\n",
    "# inf_values = np.isinf(training_data.select_dtypes(include=['float64', 'float32'])).sum()\n",
    "# print(\"Infinite values:\\n\", inf_values[inf_values > 0])\n",
    "\n",
    "# # Check column data types\n",
    "# print(training_data.dtypes)\n",
    "\n",
    "# # Check for extremely large values\n",
    "# for col in training_data.select_dtypes(include=['float64', 'float32']).columns:\n",
    "#     if training_data[col].max() > 1e20:  # Adjust threshold as needed\n",
    "#         print(f\"Column {col} has extremely large values: {training_data[col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeaccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data['ph_kd_ratio_max_Team0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b6357",
   "metadata": {},
   "source": [
    "Create training split. Currently 25% test, team_o_win prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a77f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "y = training_data['team_0_win']\n",
    "X = training_data.drop(columns=['team_0_win'])\n",
    "\n",
    "# Split  data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "267b701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  match_id  p_total_time_played_min_Team0  \\\n",
      "571         571  38721421                         490949   \n",
      "707         707  38735600                         385277   \n",
      "548         548  38719367                         828878   \n",
      "176         176  38673339                         781368   \n",
      "291         291  38690827                        1147443   \n",
      "..          ...       ...                            ...   \n",
      "71           71  38660058                         658377   \n",
      "106         106  38664946                         909952   \n",
      "270         270  38688592                         303190   \n",
      "435         435  38706622                          77608   \n",
      "102         102  38664450                         955101   \n",
      "\n",
      "     p_total_time_played_min_Team1  p_total_time_played_max_Team0  \\\n",
      "571                         146121                        1863994   \n",
      "707                         231665                        5080198   \n",
      "548                         231304                        3227511   \n",
      "176                         935558                        3496972   \n",
      "291                         434823                        2539776   \n",
      "..                             ...                            ...   \n",
      "71                          555003                        4870406   \n",
      "106                         185780                        3927884   \n",
      "270                         497786                        3288470   \n",
      "435                          75817                        3598771   \n",
      "102                         282240                        3697001   \n",
      "\n",
      "     p_total_time_played_max_Team1  p_total_time_played_mean_Team0  \\\n",
      "571                        3559223                      1309390.00   \n",
      "707                        2538268                      2430599.33   \n",
      "548                        3386954                      1888384.33   \n",
      "176                        3490014                      2084325.17   \n",
      "291                        3892498                      1926541.67   \n",
      "..                             ...                             ...   \n",
      "71                         3479175                      2407570.33   \n",
      "106                        3304523                      1977292.17   \n",
      "270                        5428791                      1539719.33   \n",
      "435                        2947704                      1306355.00   \n",
      "102                        3713240                      2548302.67   \n",
      "\n",
      "     p_total_time_played_mean_Team1  p_total_time_played_std_Team0  \\\n",
      "571                      1655314.50                      542371.61   \n",
      "707                      1573686.17                     1722119.98   \n",
      "548                      2122277.50                     1098606.22   \n",
      "176                      2665020.00                     1064768.33   \n",
      "291                      1930498.67                      558055.09   \n",
      "..                              ...                            ...   \n",
      "71                       2219594.33                     1815823.37   \n",
      "106                      1551807.33                     1214617.42   \n",
      "270                      2813374.17                     1049446.27   \n",
      "435                      1619030.83                     1388405.03   \n",
      "102                      2262036.17                     1245969.37   \n",
      "\n",
      "     p_total_time_played_std_Team1  ...  ph_assists_ratio_std_Team0  \\\n",
      "571                     1380754.83  ...                        2.56   \n",
      "707                      943670.71  ...                       13.62   \n",
      "548                     1375190.77  ...                        6.61   \n",
      "176                      935575.48  ...                        4.26   \n",
      "291                     1251762.50  ...                        5.54   \n",
      "..                             ...  ...                         ...   \n",
      "71                      1053033.02  ...                        3.15   \n",
      "106                     1325708.53  ...                        5.16   \n",
      "270                     1658802.94  ...                        4.93   \n",
      "435                     1056566.08  ...                       12.19   \n",
      "102                     1190394.94  ...                        3.95   \n",
      "\n",
      "     ph_assists_ratio_std_Team1  ph_win_rate_ratio_min_Team0  \\\n",
      "571                        1.79                         0.93   \n",
      "707                        6.43                         0.97   \n",
      "548                        8.78                         1.03   \n",
      "176                       11.24                         0.91   \n",
      "291                        5.19                         1.01   \n",
      "..                          ...                          ...   \n",
      "71                         7.00                         0.55   \n",
      "106                       18.48                         0.92   \n",
      "270                        2.62                         0.91   \n",
      "435                        8.04                         1.12   \n",
      "102                        5.03                         1.06   \n",
      "\n",
      "     ph_win_rate_ratio_min_Team1  ph_win_rate_ratio_max_Team0  \\\n",
      "571                         1.05                         1.28   \n",
      "707                         1.06                         1.17   \n",
      "548                         1.02                         1.50   \n",
      "176                         0.93                         1.22   \n",
      "291                         0.91                         1.24   \n",
      "..                           ...                          ...   \n",
      "71                          0.93                         1.20   \n",
      "106                         0.72                         1.27   \n",
      "270                         1.00                         1.32   \n",
      "435                         1.05                         1.46   \n",
      "102                         0.98                         1.59   \n",
      "\n",
      "     ph_win_rate_ratio_max_Team1  ph_win_rate_ratio_mean_Team0  \\\n",
      "571                         1.49                          1.07   \n",
      "707                         1.58                          1.10   \n",
      "548                         1.28                          1.22   \n",
      "176                         1.19                          1.14   \n",
      "291                         1.23                          1.14   \n",
      "..                           ...                           ...   \n",
      "71                          1.24                          1.03   \n",
      "106                         1.50                          1.07   \n",
      "270                         1.24                          1.08   \n",
      "435                         1.37                          1.25   \n",
      "102                         1.25                          1.25   \n",
      "\n",
      "     ph_win_rate_ratio_mean_Team1  ph_win_rate_ratio_std_Team0  \\\n",
      "571                          1.20                         0.12   \n",
      "707                          1.29                         0.08   \n",
      "548                          1.11                         0.20   \n",
      "176                          1.02                         0.11   \n",
      "291                          1.10                         0.09   \n",
      "..                            ...                          ...   \n",
      "71                           1.13                         0.25   \n",
      "106                          1.11                         0.11   \n",
      "270                          1.11                         0.14   \n",
      "435                          1.17                         0.15   \n",
      "102                          1.11                         0.19   \n",
      "\n",
      "     ph_win_rate_ratio_std_Team1  \n",
      "571                         0.15  \n",
      "707                         0.24  \n",
      "548                         0.10  \n",
      "176                         0.09  \n",
      "291                         0.11  \n",
      "..                           ...  \n",
      "71                          0.11  \n",
      "106                         0.32  \n",
      "270                         0.08  \n",
      "435                         0.11  \n",
      "102                         0.10  \n",
      "\n",
      "[531 rows x 106 columns]\n",
      "\n",
      "\n",
      "y_train\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(f\"\\n\\ny_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76490de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, X_test, y_train, y_test, params):\n",
    "\n",
    "    # Create unique model identifier\n",
    "    ## {model_type} {date_time} {random_state}\n",
    "    from datetime import datetime\n",
    "\n",
    "    model_type = \"rf_std\"\n",
    "    date_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_id = f\"{model_type}_{date_time}_{params.get('random_state', 42)}\"\n",
    "\n",
    "    # Initialize the model with these starting parameters\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=params.get(\"n_estimators\", 100),\n",
    "        max_depth=params.get(\"max_depth\", None),\n",
    "        min_samples_split=params.get(\"min_samples_split\", 2),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "        max_features=params.get(\"max_features\", \"sqrt\"),\n",
    "        random_state=params.get(\"random_state\", 42),\n",
    "        n_jobs=-1                # Use all available cores\n",
    "    )\n",
    "    \n",
    "    # Print Model params and start\n",
    "    print(f\"Starting Training, Modelid = {model_id}\")\n",
    "    print(\"Training Random Forest with parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "    return rf_model, model_id, y_pred\n",
    "\n",
    "def evaluate_model(model, y_test, y_pred)-> dict:\n",
    "    \"\"\"Create a report evaluating model passed, returns dict of report data\"\"\"\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred).tolist()\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {'feature': X.columns, 'importance': model.feature_importances_},\n",
    "    ).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nTop 25 important features:\")\n",
    "    print(feature_importance.head(25))\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'feature_importance': feature_importance.to_dict(orient='records')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4d9fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Params\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"random_state\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ed922bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training, Modelid = rf_std_20250817_125003_42\n",
      "Training Random Forest with parameters:\n",
      "n_estimators: 100\n",
      "max_depth: None\n",
      "min_samples_split: 2\n",
      "min_samples_leaf: 1\n",
      "max_features: sqrt\n",
      "random_state: 42\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, model_id, y_pred = \u001b[43mtrain_random_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_random_forest\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, params)\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m     32\u001b[39m y_pred = rf_model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:375\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    373\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n\u001b[32m    374\u001b[39m missing_values_in_feature_mask = (\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_compute_missing_values_in_feature_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m )\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    381\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:222\u001b[39m, in \u001b[36mBaseDecisionTree._compute_missing_values_in_feature_mask\u001b[39m\u001b[34m(self, X, estimator_name)\u001b[39m\n\u001b[32m    218\u001b[39m     overall_sum = np.sum(X)\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(overall_sum):\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# Raise a ValueError in case of the presence of an infinite element.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# If the sum is not nan, then there are no missing values\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isnan(overall_sum):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Local Code\\deadlock_match_prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "model, model_id, y_pred = train_random_forest(X_train, X_test, y_train, y_test, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "012f3188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6629\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.65      0.70      0.67        88\n",
      "           Y       0.68      0.62      0.65        90\n",
      "\n",
      "    accuracy                           0.66       178\n",
      "   macro avg       0.66      0.66      0.66       178\n",
      "weighted avg       0.66      0.66      0.66       178\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62 26]\n",
      " [34 56]]\n",
      "\n",
      "Top 25 important features:\n",
      "                               feature  importance\n",
      "123        ph_win_rate_ratio_min_Team1    0.022840\n",
      "125        ph_win_rate_ratio_max_Team1    0.022370\n",
      "126        ph_win_rate_ratio_q25_Team0    0.021401\n",
      "122        ph_win_rate_ratio_min_Team0    0.019266\n",
      "124        ph_win_rate_ratio_max_Team0    0.017883\n",
      "128     ph_win_rate_ratio_median_Team0    0.016599\n",
      "130        ph_win_rate_ratio_q75_Team0    0.014678\n",
      "127        ph_win_rate_ratio_q25_Team1    0.014486\n",
      "131        ph_win_rate_ratio_q75_Team1    0.012987\n",
      "129     ph_win_rate_ratio_median_Team1    0.011821\n",
      "55         ph_damage_per_min_max_Team1    0.011037\n",
      "6        p_total_time_played_q25_Team0    0.010853\n",
      "16                   ph_wins_q25_Team0    0.010408\n",
      "104  ph_damage_per_min_ratio_max_Team0    0.009730\n",
      "78            ph_total_kd_median_Team0    0.009545\n",
      "52         ph_damage_per_min_min_Team0    0.009539\n",
      "11       p_total_time_played_q75_Team1    0.009417\n",
      "79            ph_total_kd_median_Team1    0.009396\n",
      "59      ph_damage_per_min_median_Team1    0.009348\n",
      "72               ph_total_kd_min_Team0    0.009347\n",
      "4        p_total_time_played_max_Team0    0.009091\n",
      "13                   ph_wins_min_Team1    0.008895\n",
      "29               ph_kills_median_Team1    0.008759\n",
      "3        p_total_time_played_min_Team1    0.008721\n",
      "101     ph_time_played_ratio_q75_Team1    0.008462\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_model(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd108fc",
   "metadata": {},
   "source": [
    "Save Model, parameters, trianing data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd4230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder structure for this model adjust per model\n",
    "# Currently manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7cef30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, params, folder, model_id,feature_names = X.columns):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    import joblib, json, platform, os\n",
    "\n",
    "    # create subfolders\n",
    "    os.makedirs(f\"{folder}/samples\", exist_ok=True)\n",
    "\n",
    "    joblib.dump(model, f\"{folder}/model.joblib\")\n",
    "\n",
    "    print(f\"Model saved to {folder}\")\n",
    "\n",
    "    json.dump(params, open(f\"{folder}/params.json\",\"w\"))\n",
    "\n",
    "    json.dump({\n",
    "    \"run_id\": model_id, \"python\": platform.python_version(),\n",
    "    \"feature_names\": feature_names,\"random_state\": params.get(\"random_state\", 42),\n",
    "    }, open(f\"{folder}/meta.json\",\"w\"))\n",
    "\n",
    "def save_report(results):\n",
    "    import json\n",
    "\n",
    "    with open(\"results.txt\", \"w\") as f:\n",
    "        f.write(f\"Accuracy: {results['accuracy']}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(json.dumps(results['classification_report'], indent=2))\n",
    "        f.write(\"\\n\\nConfusion Matrix:\\n\")\n",
    "        f.write(str(results['confusion_matrix']))\n",
    "        f.write(\"\\n\\nTop Features:\\n\")\n",
    "        for feat in results['feature_importance'][:25]:\n",
    "            f.write(f\"{feat['feature']}: {feat['importance']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323382f7",
   "metadata": {},
   "source": [
    "Save Model and trianing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccf051ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/8.14.25_rf_1_quantiles/\n"
     ]
    }
   ],
   "source": [
    "model_folder = \"models/8.14.25_rf_1_quantiles/\"\n",
    "features = X.columns.tolist()\n",
    "\n",
    "save_model(model, params, model_folder, model_id, features)\n",
    "save_report(report)\n",
    "\n",
    "train = X_train.copy()\n",
    "train[\"target\"] = y_train\n",
    "train.to_csv(f\"{model_folder}/samples/Xy_train.csv\", index=False)\n",
    "\n",
    "test = X_test.copy()\n",
    "test[\"target\"] = y_test\n",
    "test.to_csv(f\"{model_folder}/samples/Xy_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
